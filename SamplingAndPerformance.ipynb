{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SHeidema/AMES-TRIDSA/blob/main/SamplingAndPerformance.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make sure you install the required modules.\n"
      ],
      "metadata": {
        "id": "XUnaOjN2WBhd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install vegafusion"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YWVY5snmOCNC",
        "outputId": "69664144-effd-4bc7-e315-baefea1d8bdd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting vegafusion\n",
            "  Downloading vegafusion-1.3.0-py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: altair>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from vegafusion) (4.2.2)\n",
            "Requirement already satisfied: pyarrow>=5 in /usr/local/lib/python3.10/dist-packages (from vegafusion) (9.0.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from vegafusion) (1.5.3)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from vegafusion) (5.9.5)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair>=4.2.0->vegafusion) (0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from altair>=4.2.0->vegafusion) (3.1.2)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair>=4.2.0->vegafusion) (4.3.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from altair>=4.2.0->vegafusion) (1.22.4)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair>=4.2.0->vegafusion) (0.12.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->vegafusion) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->vegafusion) (2022.7.1)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair>=4.2.0->vegafusion) (23.1.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair>=4.2.0->vegafusion) (0.19.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->vegafusion) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->altair>=4.2.0->vegafusion) (2.1.3)\n",
            "Installing collected packages: vegafusion\n",
            "Successfully installed vegafusion-1.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ibAorHWFe_Fz",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Code adjusted from https://github.com/EAISI/machine-learning-with-python-explainers/blob/main/example-solutions/ames-housing-daniel.ipynb\n",
        "#pip install vegafusion\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sklearn\n",
        "import vegafusion as vf\n",
        "import numpy as np\n",
        "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.linear_model import Lasso, LassoCV, LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import GridSearchCV, cross_validate, train_test_split\n",
        "from sklearn.pipeline import Pipeline, make_pipeline\n",
        "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler\n",
        "from sklearn.utils import estimator_html_repr\n",
        "from xgboost import XGBRegressor\n",
        "\n",
        "# check versions\n",
        "#for library in [pd, sklearn, vf]:\n",
        "#    print(f\"using {library.__name__} version {library.__version__}\")\n",
        "\n",
        "\n",
        "# dataset\n",
        "URL = \"https://github.com/jads-nl/discover-projects/blob/main/ames-housing/AmesHousing.csv?raw=true\"\n",
        "\n",
        "# fill-value for missings in categorical variables\n",
        "MISSING = \"missing\"\n",
        "NONE = \"not present\"\n",
        "\n",
        "def standardize_column_names(s):\n",
        "    return s.replace(\" \", \"\")\n",
        "\n",
        "\n",
        "def na_means_none(df):\n",
        "    cols_na_means_none = [\n",
        "        \"Alley\",\n",
        "        \"BsmtQual\",\n",
        "        \"BsmtCond\",\n",
        "        \"BsmtFinType1\",\n",
        "        \"BsmtFinType2\",\n",
        "        \"FireplaceQu\",\n",
        "        \"GarageType\",\n",
        "        \"GarageFinish\",\n",
        "        \"GarageQual\",\n",
        "        \"GarageCond\",\n",
        "        \"PoolQC\",\n",
        "        \"Fence\",\n",
        "        \"MiscFeature\",\n",
        "    ]\n",
        "\n",
        "    df.loc[:, cols_na_means_none] = df.loc[:, cols_na_means_none].fillna(value=NONE)\n",
        "    return df\n",
        "\n",
        "\n",
        "def optimize_memory(df):\n",
        "    # objects to categorical\n",
        "    df[df.select_dtypes(include=\"object\").columns] = df.select_dtypes(\n",
        "        include=\"object\"\n",
        "    ).astype(\"category\")\n",
        "\n",
        "    # convert integers to smallest unsigned integer and floats to smallest\n",
        "    for old, new in [(\"integer\", \"unsigned\"), (\"float\", \"float\")]:\n",
        "        for col in df.select_dtypes(include=old).columns:\n",
        "            df[col] = pd.to_numeric(df[col], downcast=new)\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "df = (\n",
        "    pd.read_csv(URL)\n",
        "    .rename(columns=standardize_column_names)\n",
        "    .pipe(na_means_none)\n",
        "    .pipe(optimize_memory)\n",
        ")\n",
        "\n",
        "df_no_outliers = df.query(\"GrLivArea < 4000\")\n",
        "\n",
        "\n",
        "def na_per_columns(df):\n",
        "    \"\"\"Calculates nulls per column\"\"\"\n",
        "    nulls = df.isnull().sum()\n",
        "    return nulls[nulls != 0].sort_values(ascending=False)\n",
        "\n",
        "\n",
        "cols_with_nulls = na_per_columns(df)\n",
        "\n",
        "cols_to_drop = (cols_with_nulls[cols_with_nulls / len(df) > 0.2] / len(df)).index\n",
        "cols_with_nulls[cols_to_drop]\n",
        "\n",
        "#Model training and evaluation\n",
        "df_train, df_test = train_test_split(df_no_outliers, test_size=0.3)\n",
        "\n",
        "\n",
        "# prepare X and y, using (SalePrice) throughout\n",
        "X = df_train[df_train.columns.difference(cols_to_drop).drop(\"SalePrice\")]\n",
        "y = df_train.SalePrice\n",
        "\n",
        "# same for test set\n",
        "X_test = df_test[df_test.columns.difference(cols_to_drop).drop(\"SalePrice\")]\n",
        "y_test = df_test.SalePrice\n",
        "\n",
        "cat_cols = X.select_dtypes(include=\"category\").columns\n",
        "num_cols = X.select_dtypes(include=\"number\").columns\n",
        "\n",
        "  # need to explicitly define categories for pipeline and add MISSING category\n",
        "categories = [df[col].cat.categories.to_list() for col in cat_cols]\n",
        "for cat in categories:\n",
        "    cat.append(MISSING)\n",
        "\n",
        "  # combine all preprocessing for cat_cols in one pipeline\n",
        "preprocess_cat_cols = make_pipeline(\n",
        "    SimpleImputer(missing_values=np.nan, strategy=\"constant\", fill_value=MISSING),\n",
        "    OneHotEncoder(categories=categories),\n",
        ")\n",
        "\n",
        "  # same for num_cols\n",
        "preprocess_num_cols = make_pipeline(\n",
        "    SimpleImputer(missing_values=np.nan, strategy=\"median\"), StandardScaler()\n",
        ")\n",
        "\n",
        "  # compose dataset with make_column_transformer\n",
        "prepare_linear = make_column_transformer(\n",
        "    (preprocess_num_cols, num_cols), (preprocess_cat_cols, cat_cols), remainder=\"drop\"\n",
        ")\n",
        "\n",
        "ols = make_pipeline(prepare_linear, LinearRegression())\n",
        "\n",
        "ols_scores = cross_validate(\n",
        "    ols,\n",
        "    X,\n",
        "    y,\n",
        "    cv=5,\n",
        "    scoring=[\"neg_mean_squared_error\"],\n",
        "    return_train_score=True,\n",
        "    return_estimator=True,\n",
        ")\n",
        "\n",
        "def get_best_model(cv_scores):\n",
        "    \"\"\"\n",
        "    Return best (most conservative) model from cross_validate object.\n",
        "\n",
        "    Uses np.argmax to find bottomright point == largest RMLSE\n",
        "    \"\"\"\n",
        "    index = np.argmax(np.sqrt(-cv_scores[\"train_neg_mean_squared_error\"]))\n",
        "    model = cv_scores[\"estimator\"][index]\n",
        "    rmsle = np.sqrt(mean_squared_error(y_test, model.predict(X_test)))\n",
        "    return (model, rmsle)\n",
        "\n",
        "\n",
        "ols_best_model, ols_rmsle = get_best_model(ols_scores)\n",
        "print(f\"RMLSE found after running first block: {ols_rmsle:0.5f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Stratified sampling of the train and test data"
      ],
      "metadata": {
        "id": "h4sRkgFqsTy2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_binned = np.digitize(df_no_outliers['SalePrice'].values,np.percentile(df_no_outliers['SalePrice'].values, range(0, 100, 10)))\n",
        "\n",
        "#Stratified sampling by using the stratify= argument\n",
        "df_train, df_test = train_test_split(df_no_outliers, test_size=0.3, stratify=y_binned)\n",
        "\n",
        "X = df_train[df_train.columns.difference(cols_to_drop).drop(\"SalePrice\")]\n",
        "y = df_train.SalePrice\n",
        "\n",
        "X_test = df_test[df_test.columns.difference(cols_to_drop).drop(\"SalePrice\")]\n",
        "y_test = df_test.SalePrice\n",
        "\n",
        "ols_scores = cross_validate(\n",
        "    ols,\n",
        "    X,\n",
        "    y,\n",
        "    cv=5,\n",
        "    scoring=[\"neg_mean_squared_error\"],\n",
        "    return_train_score=True,\n",
        "    return_estimator=True,\n",
        ")\n",
        "\n",
        "ols_best_model, ols_rmsle = get_best_model(ols_scores)\n",
        "print(f\"RMLSE after running second block: {ols_rmsle:0.5f}\")"
      ],
      "metadata": {
        "id": "3EglyOkYhCRw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}